{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear, Sequential, Dropout, ReLU\n",
    "from torch import load, inference_mode, round, sigmoid\n",
    "from sklearn import metrics\n",
    "from torchvision.models.regnet import regnet_y_3_2gf, RegNet_Y_3_2GF_Weights, regnet_y_8gf, RegNet_Y_8GF_Weights\n",
    "from torchvision.models.swin_transformer import swin_v2_t, Swin_V2_T_Weights\n",
    "from torchvision.models.efficientnet import efficientnet_v2_s, EfficientNet_V2_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import ImagesOnlyDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = pd.read_csv(\"../Data/Processed/test_targets.csv\")\n",
    "test_features = pd.read_csv(\"../Data/Processed/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_RegNet = ImagesOnlyDataset(test_features['filename'], test_targets, \"../Data/images\", 232, 224, False)\n",
    "test_dataset_EfficientNet = ImagesOnlyDataset(test_features['filename'], test_targets, \"../Data/images\", 384, 384, False)\n",
    "test_dataset_SwinV2 = ImagesOnlyDataset(test_features['filename'], test_targets, \"../Data/images\", 260, 256, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_regnet = DataLoader(test_dataset_RegNet, 16, True)\n",
    "test_dataloader_efficientnet = DataLoader(test_dataset_EfficientNet, 16, True)\n",
    "test_dataloader_swinv2 = DataLoader(test_dataset_SwinV2, 16, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RegNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regnet_model = regnet_y_3_2gf()\n",
    "regnet_model.fc = Linear(1512, 22)\n",
    "regnet_model.load_state_dict(load(\"../Models/FinetunedRegNet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 17.957M\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in regnet_model.parameters())\n",
    "print(\"Number of Parameters: %.3fM\" % (total_params/1e6,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Larget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regnet_model_large = regnet_y_8gf()\n",
    "regnet_model_large.fc = Linear(2016, 22)\n",
    "regnet_model_large.load_state_dict(load(\"../Models/FinetunedRegNetY.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 37.409M\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in regnet_model_large.parameters())\n",
    "print(\"Number of Parameters: %.3fM\" % (total_params/1e6,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_model = efficientnet_v2_s()\n",
    "efficientnet_model.classifier = Sequential(\n",
    "    Dropout(p=0.2),\n",
    "    ReLU(),\n",
    "    Linear(in_features=1280, out_features=22)\n",
    ")\n",
    "efficientnet_model.load_state_dict(load(\"../Models/FinetunedEfficientNet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 20.206M\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in efficientnet_model.parameters())\n",
    "print(\"Number of Parameters: %.3fM\" % (total_params/1e6,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwinV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swinv2_model = swin_v2_t()\n",
    "swinv2_model.head = Linear(768, 22)\n",
    "swinv2_model.load_state_dict(load(\"../Models/FinetunedSwinV2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 27.599M\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in swinv2_model.parameters())\n",
    "print(\"Number of Parameters: %.3fM\" % (total_params/1e6,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.55%\n"
     ]
    }
   ],
   "source": [
    "regnet_true_labels = []\n",
    "regnet_pred_labels = []\n",
    "regnet_model.eval()\n",
    "with inference_mode():\n",
    "    for batch, labels in test_dataloader_regnet:\n",
    "        outputs = regnet_model(batch)\n",
    "        preds = round(sigmoid(outputs))\n",
    "        regnet_true_labels.extend(labels.cpu().numpy())\n",
    "        regnet_pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "regnet_true_labels = np.array(regnet_true_labels)\n",
    "regnet_pred_labels = np.array(regnet_pred_labels)\n",
    "\n",
    "regnet_accuracy = metrics.accuracy_score(regnet_true_labels, regnet_pred_labels)\n",
    "\n",
    "print(f'Accuracy: {regnet_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.55%\n"
     ]
    }
   ],
   "source": [
    "regnet_large_true_labels = []\n",
    "regnet_large_pred_labels = []\n",
    "regnet_model_large.eval()\n",
    "with inference_mode():\n",
    "    for batch, labels in test_dataloader_regnet:\n",
    "        outputs = regnet_model_large(batch)\n",
    "        preds = round(sigmoid(outputs))\n",
    "        regnet_large_true_labels.extend(labels.cpu().numpy())\n",
    "        regnet_large_pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "regnet_large_true_labels = np.array(regnet_large_true_labels)\n",
    "regnet_large_pred_labels = np.array(regnet_large_pred_labels)\n",
    "\n",
    "regnet_large_accuracy = metrics.accuracy_score(regnet_large_true_labels, regnet_large_pred_labels)\n",
    "\n",
    "print(f'Accuracy: {regnet_large_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.03%\n"
     ]
    }
   ],
   "source": [
    "efficientnet_true_labels = []\n",
    "efficientnet_pred_labels = []\n",
    "efficientnet_model.eval()\n",
    "with inference_mode():\n",
    "    for batch, labels in test_dataloader_efficientnet:\n",
    "        outputs = efficientnet_model(batch)\n",
    "        preds = round(sigmoid(outputs))\n",
    "        efficientnet_true_labels.extend(labels.cpu().numpy())\n",
    "        efficientnet_pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "efficientnet_true_labels = np.array(efficientnet_true_labels)\n",
    "efficientnet_pred_labels = np.array(efficientnet_pred_labels)\n",
    "\n",
    "efficientnet_accuracy = metrics.accuracy_score(efficientnet_true_labels, efficientnet_pred_labels)\n",
    "\n",
    "print(f'Accuracy: {efficientnet_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swinv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.67%\n"
     ]
    }
   ],
   "source": [
    "swinv2_true_labels = []\n",
    "swinv2_pred_labels = []\n",
    "swinv2_model.eval()\n",
    "with inference_mode():\n",
    "    for batch, labels in test_dataloader_swinv2:\n",
    "        outputs = swinv2_model(batch)\n",
    "        preds = round(sigmoid(outputs))\n",
    "        swinv2_true_labels.extend(labels.cpu().numpy())\n",
    "        swinv2_pred_labels.extend(preds.cpu().numpy())\n",
    "\n",
    "swinv2_true_labels = np.array(swinv2_true_labels)\n",
    "swinv2_pred_labels = np.array(swinv2_pred_labels)\n",
    "\n",
    "swinv2_accuracy = metrics.accuracy_score(swinv2_true_labels, swinv2_pred_labels)\n",
    "\n",
    "print(f'Accuracy: {swinv2_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.38      0.53        13\n",
      "           1       0.89      0.80      0.84        99\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      0.67      0.80         6\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       1.00      0.50      0.67         2\n",
      "          12       0.25      0.25      0.25         4\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      0.50      0.67         6\n",
      "          15       0.95      0.96      0.96       141\n",
      "          16       0.75      1.00      0.86         3\n",
      "          17       0.50      0.25      0.33         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.93      0.81      0.87       107\n",
      "          21       0.93      0.93      0.93        15\n",
      "\n",
      "   micro avg       0.91      0.81      0.86       417\n",
      "   macro avg       0.59      0.48      0.52       417\n",
      "weighted avg       0.89      0.81      0.84       417\n",
      " samples avg       0.90      0.81      0.83       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regnet_cf = metrics.multilabel_confusion_matrix(regnet_true_labels, regnet_pred_labels)\n",
    "print(metrics.classification_report(regnet_true_labels, regnet_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.88      0.83      0.85        99\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.33      0.17      0.22         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.33      0.17      0.22         6\n",
      "          15       0.96      0.98      0.97       141\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.92      0.83      0.87       107\n",
      "          21       0.88      0.93      0.90        15\n",
      "\n",
      "   micro avg       0.91      0.78      0.84       417\n",
      "   macro avg       0.20      0.18      0.18       417\n",
      "weighted avg       0.81      0.78      0.79       417\n",
      " samples avg       0.90      0.77      0.80       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "efficientnet_cf = metrics.multilabel_confusion_matrix(efficientnet_true_labels, efficientnet_pred_labels)\n",
    "print(metrics.classification_report(efficientnet_true_labels, efficientnet_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        13\n",
      "           1       0.65      0.82      0.72        99\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.94      0.95      0.94       141\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.70      0.84      0.76       107\n",
      "          21       0.63      0.80      0.71        15\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       417\n",
      "   macro avg       0.13      0.15      0.14       417\n",
      "weighted avg       0.67      0.76      0.71       417\n",
      " samples avg       0.75      0.75      0.73       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swinv2_cf = metrics.multilabel_confusion_matrix(swinv2_true_labels, swinv2_pred_labels)\n",
    "print(metrics.classification_report(swinv2_true_labels, swinv2_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.31      0.44        13\n",
      "           1       0.86      0.89      0.88        99\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       0.43      0.50      0.46         6\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       1.00      0.50      0.67         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       1.00      0.50      0.67         2\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.50      0.50      0.50         6\n",
      "          15       0.94      0.95      0.95       141\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       0.50      0.25      0.33         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.86      0.88      0.87       107\n",
      "          21       0.88      0.93      0.90        15\n",
      "\n",
      "   micro avg       0.87      0.83      0.85       417\n",
      "   macro avg       0.49      0.42      0.44       417\n",
      "weighted avg       0.84      0.83      0.83       417\n",
      " samples avg       0.86      0.82      0.82       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regnety_cf = metrics.multilabel_confusion_matrix(regnet_large_true_labels, regnet_large_pred_labels)\n",
    "print(metrics.classification_report(regnet_large_true_labels, regnet_large_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
